# ğŸ§  Local RAG Chatbot - Pizza Reviews ğŸ•

This is a lightweight Retrieval-Augmented Generation (RAG) demo using [LangChain](https://github.com/langchain-ai/langchain), [Ollama](https://github.com/ollama/ollama), [Chroma](https://github.com/chroma-core/chroma), and [LLaMA 3](https://ollama.com/library/llama3). It answers questions based on real-world restaurant review data.

---

## ğŸ” Features

- ğŸ”— RAG pipeline using LangChain
- ğŸ§  Local inference via Ollama + LLaMA 3
- ğŸ’¾ Embedding-based retrieval with ChromaDB
- ğŸ“„ Input data from realistic restaurant reviews (CSV)
- ğŸ–¥ï¸ Simple command-line interface

---

## ğŸ“¦ Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com) installed and running
- Pull required models:
  \`\`\`
  ollama pull llama3
  ollama pull mxbai-embed-large
  \`\`\`

---

## âš™ï¸ Setup

\`\`\`
git clone https://github.com/BhagyeshPatil2004/local-rag-pizza-chatbot.git
cd local-rag-pizza-chatbot
python -m venv .venv
source .venv/bin/activate   # or use .venv\Scripts\activate on Windows
pip install -r requirements.txt
\`\`\`

---

## ğŸš€ Run the App

\`\`\`
python RAG/main.py
\`\`\`

Youâ€™ll be prompted to ask questions like:

\`\`\`
Ask your question (q to quit): tell me pizza under \$25
\`\`\`

---

## ğŸ“ Project Structure

\`\`\`
â”œâ”€â”€ RAG/

â”‚   â”œâ”€â”€ main.py           # CLI-based chatbot logic

â”‚   â”œâ”€â”€ vector.py         # Embedding + Chroma setup

â”œâ”€â”€ realistic_restaurant_reviews.csv  # Input review dataset

â”œâ”€â”€ requirements.txt      # Python dependencies

â””â”€â”€ README.md             # This file
\`\`\`

---

## ğŸ§ª Sample Questions

- "Tell me pizza under \$25"
- "How are the vegan options?"
- "What do reviews say about customer service?"

---

## ğŸ“Œ Notes

- No OpenAI API key is needed.
- All models and data processing are **100% local**.
- You can swap the dataset or tweak the prompt template for other domains.

---

## ğŸ‘¨â€ğŸ’» Author

[Bhagyesh Patil](https://github.com/BhagyeshPatil2004)
